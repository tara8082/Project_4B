{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('metis': conda)",
   "display_name": "Python 3.8.5 64-bit ('metis': conda)",
   "metadata": {
    "interpreter": {
     "hash": "ddd4d743fd1d38e605abc3a37886e115f06419814ac94d7a1c9c2c18274a5f3d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Topic Modeling on Headline Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     /Users/Tara8082/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Python support modules\n",
    "import re\n",
    "import string\n",
    "import datetime\n",
    "import pickle \n",
    "from collections import Counter\n",
    "\n",
    "# Spacy\n",
    "import spacy\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "#import en_core_web_smf\n",
    "from spacy.pipeline import SentenceSegmenter\n",
    "\n",
    "# CorEx\n",
    "#from corextopic import corextopic as ct\n",
    "#from corextopic import vis_topic as vt\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import words, stopwords, wordnet\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Helper functions in py file\n",
    "#from preprocessing_tweets import cleaned_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/Tara8082/GIT/ProjectGIT/Project_4/processed_headlines.pkl', 'rb') as read_file:\n",
    "    headlines = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                             content  \\\n",
       "0  Biden leads Trump among Hispanic voters, 62% t...   \n",
       "1  “We can’t keep up with the laundry.” Covid-19 ...   \n",
       "2  A large English study showed the number of peo...   \n",
       "3  The leaders of Microsoft, Coca-Cola, American ...   \n",
       "4  After seven months of isolation, the pull of g...   \n",
       "5  Doctors have begun to unlock the mystery behin...   \n",
       "6  Is eating in covered outdoor setups less risky...   \n",
       "7  Investors are relying on polls showing former ...   \n",
       "8  More than 91 million ballots have been cast ah...   \n",
       "9  Pricing an item at $1.99 instead of $2.00 is a...   \n",
       "\n",
       "                                       clean_content  \\\n",
       "0  biden leads trump among hispanic voters to a w...   \n",
       "1   we can t keep up with the laundry   covid has...   \n",
       "2  a large english study showed the number of peo...   \n",
       "3  the leaders of microsoft coca cola american ai...   \n",
       "4  after seven months of isolation the pull of ge...   \n",
       "5  doctors have begun to unlock the mystery behin...   \n",
       "6  is eating in covered outdoor setups less risky...   \n",
       "7  investors are relying on polls showing former ...   \n",
       "8  more than million ballots have been cast ahead...   \n",
       "9  pricing an item at instead of is a common mark...   \n",
       "\n",
       "                                           processed  \n",
       "0     biden lead trump hispanic voter telemundo poll  \n",
       "1  laundry covid tourism industry upside create h...  \n",
       "2  english study covid antibody decline significa...  \n",
       "3  leader microsoft coca colon american airline c...  \n",
       "4  month isolation pull get strong covid hospital...  \n",
       "5  doctor begin unlock mystery covid hauler badly...  \n",
       "6               eat cover outdoor setup risky inside  \n",
       "7  investor rely poll former vice president joe b...  \n",
       "8  million ballot cast ahead election party fight...  \n",
       "9  price item instead common market strategy cons...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>clean_content</th>\n      <th>processed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Biden leads Trump among Hispanic voters, 62% t...</td>\n      <td>biden leads trump among hispanic voters to a w...</td>\n      <td>biden lead trump hispanic voter telemundo poll</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>“We can’t keep up with the laundry.” Covid-19 ...</td>\n      <td>we can t keep up with the laundry   covid has...</td>\n      <td>laundry covid tourism industry upside create h...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A large English study showed the number of peo...</td>\n      <td>a large english study showed the number of peo...</td>\n      <td>english study covid antibody decline significa...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The leaders of Microsoft, Coca-Cola, American ...</td>\n      <td>the leaders of microsoft coca cola american ai...</td>\n      <td>leader microsoft coca colon american airline c...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>After seven months of isolation, the pull of g...</td>\n      <td>after seven months of isolation the pull of ge...</td>\n      <td>month isolation pull get strong covid hospital...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Doctors have begun to unlock the mystery behin...</td>\n      <td>doctors have begun to unlock the mystery behin...</td>\n      <td>doctor begin unlock mystery covid hauler badly...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Is eating in covered outdoor setups less risky...</td>\n      <td>is eating in covered outdoor setups less risky...</td>\n      <td>eat cover outdoor setup risky inside</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Investors are relying on polls showing former ...</td>\n      <td>investors are relying on polls showing former ...</td>\n      <td>investor rely poll former vice president joe b...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>More than 91 million ballots have been cast ah...</td>\n      <td>more than million ballots have been cast ahead...</td>\n      <td>million ballot cast ahead election party fight...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Pricing an item at $1.99 instead of $2.00 is a...</td>\n      <td>pricing an item at instead of is a common mark...</td>\n      <td>price item instead common market strategy cons...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "headlines.head(10)"
   ]
  },
  {
   "source": [
    "## Setting Up Word Vectorizers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        10  100  1000000  11  12  14  15  16  17  20  ...  zumpee  zumper  \\\n",
       "0        0    0        0   0   0   0   0   0   0   0  ...       0       0   \n",
       "1        0    0        0   0   0   0   0   0   0   0  ...       0       0   \n",
       "2        0    0        0   0   0   0   0   0   0   0  ...       0       0   \n",
       "3        0    0        0   0   0   0   0   0   0   0  ...       0       0   \n",
       "4        0    0        0   0   0   0   0   0   0   0  ...       0       0   \n",
       "...     ..  ...      ...  ..  ..  ..  ..  ..  ..  ..  ...     ...     ...   \n",
       "524995   0    0        0   0   0   0   0   0   0   0  ...       0       0   \n",
       "524996   0    0        0   0   0   0   0   0   0   0  ...       0       0   \n",
       "524997   0    0        0   0   0   0   0   0   0   0  ...       0       0   \n",
       "524998   0    0        0   0   0   0   0   0   0   0  ...       0       0   \n",
       "524999   0    0        0   0   0   0   0   0   0   0  ...       0       0   \n",
       "\n",
       "        zumwalt  zuniga  zuoling  zupevc  zura  zurabichvili  zurcher  zurich  \n",
       "0             0       0        0       0     0             0        0       0  \n",
       "1             0       0        0       0     0             0        0       0  \n",
       "2             0       0        0       0     0             0        0       0  \n",
       "3             0       0        0       0     0             0        0       0  \n",
       "4             0       0        0       0     0             0        0       0  \n",
       "...         ...     ...      ...     ...   ...           ...      ...     ...  \n",
       "524995        0       0        0       0     0             0        0       0  \n",
       "524996        0       0        0       0     0             0        0       0  \n",
       "524997        0       0        0       0     0             0        0       0  \n",
       "524998        0       0        0       0     0             0        0       0  \n",
       "524999        0       0        0       0     0             0        0       0  \n",
       "\n",
       "[525000 rows x 71266 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>10</th>\n      <th>100</th>\n      <th>1000000</th>\n      <th>11</th>\n      <th>12</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>20</th>\n      <th>...</th>\n      <th>zumpee</th>\n      <th>zumper</th>\n      <th>zumwalt</th>\n      <th>zuniga</th>\n      <th>zuoling</th>\n      <th>zupevc</th>\n      <th>zura</th>\n      <th>zurabichvili</th>\n      <th>zurcher</th>\n      <th>zurich</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>524995</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>524996</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>524997</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>524998</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>524999</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>525000 rows × 71266 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "doc_word = cv.fit_transform(headlines['processed'])\n",
    "vect = pd.DataFrame(doc_word.toarray(),columns=cv.get_feature_names())\n",
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         10  100  1000000   11   12   14   15   16   17   20  ...  zumpee  \\\n",
       "0       0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0   \n",
       "1       0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0   \n",
       "2       0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0   \n",
       "3       0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0   \n",
       "4       0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0   \n",
       "...     ...  ...      ...  ...  ...  ...  ...  ...  ...  ...  ...     ...   \n",
       "524995  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0   \n",
       "524996  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0   \n",
       "524997  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0   \n",
       "524998  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0   \n",
       "524999  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0   \n",
       "\n",
       "        zumper  zumwalt  zuniga  zuoling  zupevc  zura  zurabichvili  zurcher  \\\n",
       "0          0.0      0.0     0.0      0.0     0.0   0.0           0.0      0.0   \n",
       "1          0.0      0.0     0.0      0.0     0.0   0.0           0.0      0.0   \n",
       "2          0.0      0.0     0.0      0.0     0.0   0.0           0.0      0.0   \n",
       "3          0.0      0.0     0.0      0.0     0.0   0.0           0.0      0.0   \n",
       "4          0.0      0.0     0.0      0.0     0.0   0.0           0.0      0.0   \n",
       "...        ...      ...     ...      ...     ...   ...           ...      ...   \n",
       "524995     0.0      0.0     0.0      0.0     0.0   0.0           0.0      0.0   \n",
       "524996     0.0      0.0     0.0      0.0     0.0   0.0           0.0      0.0   \n",
       "524997     0.0      0.0     0.0      0.0     0.0   0.0           0.0      0.0   \n",
       "524998     0.0      0.0     0.0      0.0     0.0   0.0           0.0      0.0   \n",
       "524999     0.0      0.0     0.0      0.0     0.0   0.0           0.0      0.0   \n",
       "\n",
       "        zurich  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  \n",
       "...        ...  \n",
       "524995     0.0  \n",
       "524996     0.0  \n",
       "524997     0.0  \n",
       "524998     0.0  \n",
       "524999     0.0  \n",
       "\n",
       "[525000 rows x 71266 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>10</th>\n      <th>100</th>\n      <th>1000000</th>\n      <th>11</th>\n      <th>12</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>20</th>\n      <th>...</th>\n      <th>zumpee</th>\n      <th>zumper</th>\n      <th>zumwalt</th>\n      <th>zuniga</th>\n      <th>zuoling</th>\n      <th>zupevc</th>\n      <th>zura</th>\n      <th>zurabichvili</th>\n      <th>zurcher</th>\n      <th>zurich</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>524995</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>524996</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>524997</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>524998</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>524999</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>525000 rows × 71266 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "doc_word = tfidf.fit_transform(headlines['processed'])\n",
    "tfidf_matrix = pd.DataFrame(doc_word.toarray(),columns=cv.get_feature_names())\n",
    "tfidf_matrix"
   ]
  },
  {
   "source": [
    "# Topic Modeling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## LDA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                             content  \\\n",
       "0  Biden leads Trump among Hispanic voters, 62% t...   \n",
       "1  “We can’t keep up with the laundry.” Covid-19 ...   \n",
       "\n",
       "                                       clean_content  \\\n",
       "0  biden leads trump among hispanic voters to a w...   \n",
       "1   we can t keep up with the laundry   covid has...   \n",
       "\n",
       "                                           processed  \n",
       "0     biden lead trump hispanic voter telemundo poll  \n",
       "1  laundry covid tourism industry upside create h...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>clean_content</th>\n      <th>processed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Biden leads Trump among Hispanic voters, 62% t...</td>\n      <td>biden leads trump among hispanic voters to a w...</td>\n      <td>biden lead trump hispanic voter telemundo poll</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>“We can’t keep up with the laundry.” Covid-19 ...</td>\n      <td>we can t keep up with the laundry   covid has...</td>\n      <td>laundry covid tourism industry upside create h...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "headlines.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_headlines = headlines['processed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 6min 3s, sys: 1min 43s, total: 7min 47s\nWall time: 7min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=True, ngram_range=(1, 3))\n",
    "\n",
    "svd_model = TruncatedSVD(n_components=10, \n",
    "                        algorithm='randomized',\n",
    "                        n_iter=50,\n",
    "                        random_state=42)\n",
    "\n",
    "# pipeline of tf-idf + SVD, fit and applied to docs: \n",
    "\n",
    "svd_transformer = Pipeline([('tfidf', vectorizer),\n",
    "                           ('svd', svd_model)])\n",
    "\n",
    "svd_matrix = svd_transformer.fit_transform(processed_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Topic 0: \n",
      "front\n",
      "front wall\n",
      "front wall street\n",
      "look front wall\n",
      "look front\n",
      "street journal\n",
      "wall street journal\n",
      "journal\n",
      "wall street\n",
      "wall\n",
      "\n",
      "Topic 1: \n",
      "front financial\n",
      "front financial time\n",
      "financial time\n",
      "publish front\n",
      "publish front financial\n",
      "publish\n",
      "financial\n",
      "time\n",
      "financial time international\n",
      "time international\n",
      "\n",
      "Topic 2: \n",
      "coronavirus\n",
      "trump\n",
      "president\n",
      "president trump\n",
      "pandemic\n",
      "covid\n",
      "biden\n",
      "coronavirus pandemic\n",
      "test\n",
      "house\n",
      "\n",
      "Topic 3: \n",
      "quote\n",
      "quote rocketmortgage\n",
      "rocketmortgage\n",
      "trump\n",
      "president\n",
      "birthday\n",
      "honor\n",
      "biden\n",
      "honor birthday\n",
      "quote powerwomen\n",
      "\n",
      "Topic 4: \n",
      "coronavirus\n",
      "pandemic\n",
      "coronavirus pandemic\n",
      "death\n",
      "test\n",
      "report\n",
      "outbreak\n",
      "spread\n",
      "covid\n",
      "coronavirus death\n",
      "\n",
      "Topic 5: \n",
      "start\n",
      "europe start\n",
      "europe\n",
      "read\n",
      "sleep read\n",
      "sleep\n",
      "hong\n",
      "kong\n",
      "hong kong\n",
      "police\n",
      "\n",
      "Topic 6: \n",
      "read\n",
      "sleep read\n",
      "sleep\n",
      "hong\n",
      "hong kong\n",
      "kong\n",
      "york sleep read\n",
      "york sleep\n",
      "york\n",
      "hong kong sleep\n",
      "\n",
      "Topic 7: \n",
      "coronavirus\n",
      "trump\n",
      "read\n",
      "president\n",
      "sleep read\n",
      "sleep\n",
      "president trump\n",
      "coronavirus pandemic\n",
      "biden\n",
      "york sleep read\n",
      "\n",
      "Topic 8: \n",
      "biden\n",
      "joe\n",
      "joe biden\n",
      "presidential\n",
      "democratic\n",
      "election\n",
      "debate\n",
      "sander\n",
      "pandemic\n",
      "campaign\n",
      "\n",
      "Topic 9: \n",
      "court\n",
      "supreme\n",
      "supreme court\n",
      "pandemic\n",
      "coronavirus pandemic\n",
      "coronavirus\n",
      "justice\n",
      "barrett\n",
      "ginsburg\n",
      "amy coney\n",
      "\n",
      "CPU times: user 1min 55s, sys: 6.16 s, total: 2min 1s\n",
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "for ix, comp in enumerate(svd_model.components_):\n",
    "    terms_comp = zip(terms, comp)\n",
    "    sorted_terms = sorted(terms_comp, key= lambda x:x[1], reverse=True)[:10]\n",
    "    print(\"Topic \"+str(ix)+\": \")\n",
    "    for t in sorted_terms:\n",
    "        print(t[0])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}